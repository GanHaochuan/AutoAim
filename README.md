# RoboMaster 自动瞄准系统 (Auto-Aim System)

## 1. 项目简介
本项目是针对机器人对抗赛（RoboMaster）开发的视觉自动瞄准系统。系统通过 OpenCV 实现对敌方装甲板灯条的实时检测、匹配组合、数字识别以及三维空间位置测距（PnP）。

本项目采用 **面向对象编程 (OOP)** 思想，将算法分解为多个独立模块，确保了代码的高度可维护性与扩展性。

### 核心功能
- [x] **灯条检测**：基于颜色通道相减与形态学处理，有效滤除环境干扰。
- [x] **装甲板匹配**：通过几何约束（角度、高度比、间距比）实现灯条配对。
- [x] **大/小装甲板区分**：根据灯条间距比自动识别装甲板类型。
- [x] **深度学习数字识别**：集成轻量级 CNN 模型，识别装甲板贴纸数字（1, 2, 3, 4, 5, 7）。
- [x] **PnP 目标测距**：利用解算位姿获取目标距离（mm）。
- [x] **可视化标注**：实时显示灯条轮廓、装甲板框、数字及距离信息。

---

## 2. 项目目录结构
遵循模块化开发规范，将声明与实现分离，并提供完整的训练脚本：

```text
AutoAim/
├── CMakeLists.txt              # CMake 构建脚本
├── generate_data.py            # 脚本：合成数字识别训练集
├── train_armor.py              # 脚本：PyTorch 模型训练与 ONNX 导出
├── data/                       # 数据资源目录
│   ├── data/                   # 分类后的数字样本 (1, 2, 3, 4, 5, 7, negative)
│   ├── camera_info.yaml        # 相机内参配置文件
│   ├── test02.mp4              # 测试视频素材 1
│   └── test03.mp4              # 测试视频素材 2
├── include/                    # 核心模块头文件
│   ├── Armor.h                 # 数据结构定义 (ArmorType, Armor struct)
│   ├── ArmorMatcher.h          # 灯条匹配器类声明
│   ├── AutoAimSystem.h         # 系统总控类声明
│   ├── LightBarDetector.h      # 灯条检测器类声明
│   └── NumberRecognizer.h      # 数字识别器类声明
├── src/                        # 核心模块源文件
│   ├── ArmorMatcher.cpp        # 灯条配对与几何筛选实现
│   ├── AutoAimSystem.cpp       # 系统状态机与 PnP 测距实现
│   ├── LightBarDetector.cpp    # 颜色提取与灯条检测实现
│   ├── NumberRecognizer.cpp    # DNN 推理与透视变换实现
│   └── main.cpp                # 程序入口
├── models/                     # 模型部署目录
│   └── armor_model.onnx        # 训练完成的数字识别模型
└── armor_model.onnx.data       # 模型相关数据文件
```

---

## 3. 算法说明

### 3.1 预处理与灯条检测 (`LightBarDetector`)
1. **颜色分离**：针对敌方颜色（红/蓝），对 BGR 通道进行相减（如 `R - B`），增强灯条对比度并抑制环境光。
2. **二值化**：利用 `cv::THRESH_OTSU` 自动阈值处理，适应不同光照环境。
3. **几何筛选**：通过 `cv::minAreaRect` 提取旋转矩形，基于长宽比、面积、倾斜角度过滤非灯条干扰。

### 3.2 匹配与分类 (`ArmorMatcher`)
- **灯条配对**：筛选满足平行度、高度相似度、中心 y 轴偏移量的灯条对。
- **类型判断**：计算 `中心距 / 灯条高度` 的比例：
  - 比例在 2.0~3.2 之间判定为 **小装甲板**。
  - 比例在 3.2~5.5 之间判定为 **大装甲板**。

### 3.3 数字识别 (`NumberRecognizer`)
- **透视变换**：使用 `cv::getPerspectiveTransform` 将倾斜的装甲板校正为 50x50 的正方形图像。
- **DNN 推理**：加载基于 PyTorch 训练的轻量级 CNN 模型（ONNX 格式），对 ROI 区域进行 6 类别数字及负样本（Negative）识别。

### 3.4 位置测距 (`solvePnP`)
- 结合装甲板真实物理尺寸（小装甲板 135mm，大装甲板 230mm）作为物点，以像素点作为像点，调用 `cv::solvePnP` 解算相机到目标的平移向量，实现 Z 轴测距。

---

## 4. 编译与运行指南

### 环境依赖
- **操作系统**: Ubuntu 20.04+ 或 Windows 10/11
- **编译器**: 支持 C++17 的 GCC/MSVC
- **库依赖**: 
    - OpenCV 4.5.0+ (需包含 dnn 模块)
    - CMake 3.10+

### 编译步骤 (C++)
```bash
# 1. 克隆项目
git clone https://github.com/GanHaochuan/AutoAim.git
cd AutoAim

# 2. 创建并进入构建目录
mkdir build && cd build

# 3. 配置 CMake 并编译
cmake ..
cmake --build . --config Debug

# 4. 运行可执行程序
.\Debug\autoaim.exe
```

### 模型训练 (Python)
若需重新训练模型：
1. 运行 `generate_data.py` 生成合成数据集。
2. 运行 `train_armor.py` 进行训练并导出 `armor_model.onnx`。

---

## 5. 开发计划与 Git 记录
本项目开发过程遵循 Git 工作流，包含以下关键提交：
- `feat: 初始化项目结构与 CMake 构建配置`
- `feat: 完成灯条配对与装甲板矩形生成`
- `feat: 使用模板方法数字识别（效果不好）`
- `feat: 使用深度学习方法数字识别`
- `refactor: 添加测距模块与大、小判断模块`
- `docs: 更新 README 指南与算法原理说明`

---

## 6. 已知问题与优化方向

在实际测试过程中，系统目前存在以下待优化的技术难点：

### 6.1 装甲板误匹配问题
*   **现象描述**：当两个装甲板距离较近时，系统偶尔会将左侧装甲板的右灯条与右侧装甲板的左灯条错误匹配，形成一个“虚假装甲板”。
*   **成因分析**：
    *   匹配逻辑主要依赖灯条间的几何比例，当两个装甲板平行且间距符合比例约束时，现有阈值难以区分。
    *   缺乏对装甲板内部区域的特征校验。
*   **拟改进方案**：
    *   **增加颜色一致性校验**：检测匹配对中间区域的平均亮度或颜色特征，虚假匹配区域通常由于缺乏中心贴纸和发光底板，其特征值与真实目标有显著差异。
    *   **引入数字识别置信度过滤**：虚假装甲板中间通常无法识别出有效数字，可通过数字识别器的反馈结果反向剔除无效匹配。

### 6.2 数字识别鲁棒性不足
*   **现象描述**：数字识别准确率低或无法识别。
*   **成因分析**：
    *   **合成数据集局限性**：目前模型主要基于 `generate_data.py` 生成的合成数据训练，缺乏真实赛场环境下灯光晕染、动态模糊等复杂特征。
    *   **透视变换精度**：PnP 排序或顶点提取的微小误差会导致裁剪出的数字图像发生畸变，影响分类器输入。
*   **拟改进方案**：
    *   **扩充真实样本集**：收集实际比赛视频并进行手动标注（Labeling），通过迁移学习（Transfer Learning）提升模型在真实环境下的表现。
    *   **优化图像预处理**：在输入 DNN 前增加自适应二值化或对比度增强（CLAHE），减少光照对数字边缘的影响。



